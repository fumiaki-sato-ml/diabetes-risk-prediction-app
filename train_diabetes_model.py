{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1NdC1KgdoixZz-BBx2ONt-l-ql37FvuaW","authorship_tag":"ABX9TyPsbj3OSDCOvlpJO157pGV1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"td8lV590lhgQ","executionInfo":{"status":"ok","timestamp":1765679852069,"user_tz":-540,"elapsed":1858,"user":{"displayName":"さとふみ","userId":"03747907895686963076"}},"outputId":"4eb26596-eccf-467f-9b95-fd55fb3d19a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/東京デジタルアカデミー/diabetes-webapp_ver2\n","=== Evaluation (hold-out test) ===\n","Accuracy: 0.7597\n","AUC     : 0.8231\n","\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       0.81      0.82      0.82       100\n","           1       0.66      0.65      0.65        54\n","\n","    accuracy                           0.76       154\n","   macro avg       0.74      0.73      0.74       154\n","weighted avg       0.76      0.76      0.76       154\n","\n","Saved model artifact: /content/drive/MyDrive/東京デジタルアカデミー/diabetes-webapp_ver2/diabetes_xgb_model.pkl\n","Saved feature importance: /content/drive/MyDrive/東京デジタルアカデミー/diabetes-webapp_ver2/feature_importance.csv\n","\n","=== Feature importance (top) ===\n","                    feature  importance\n","1                   Glucose    0.237535\n","5                       BMI    0.138559\n","7                       Age    0.126478\n","4                   Insulin    0.123893\n","6  DiabetesPedigreeFunction    0.104068\n","0               Pregnancies    0.095708\n","3             SkinThickness    0.087436\n","2             BloodPressure    0.086322\n"]}],"source":["# train_diabetes_model.py\n","import os\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n","from sklearn.impute import SimpleImputer\n","from xgboost import XGBClassifier\n","\n","RANDOM_STATE = 42\n","\n","%cd /content/drive/MyDrive/東京デジタルアカデミー/diabetes-webapp_ver2\n","\n","\n","# ===== 工夫点①：実行場所に依存しないパス解決 =====\n","\n","if \"__file__\" in globals():\n","    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n","else:\n","    BASE_DIR = os.getcwd()\n","\n","DATA_PATH = os.path.join(BASE_DIR, \"data\", \"diabetes.csv\")\n","\n","MODEL_PATH = os.path.join(BASE_DIR, \"diabetes_xgb_model.pkl\")\n","IMPORTANCE_PATH = os.path.join(BASE_DIR, \"feature_importance.csv\")\n","\n","\n","def load_data(path: str = DATA_PATH) -> pd.DataFrame:\n","    \"\"\"Pima Indians Diabetes Dataset を読み込む（data/diabetes.csv 前提）\"\"\"\n","    if not os.path.exists(path):\n","        raise FileNotFoundError(f\"CSVが見つかりません: {path}\")\n","\n","    df = pd.read_csv(path)\n","\n","    required_cols = [\n","        \"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n","        \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"\n","    ]\n","    missing = [c for c in required_cols if c not in df.columns]\n","    if missing:\n","        raise ValueError(f\"必要な列が不足しています: {missing}\")\n","\n","    return df\n","\n","\n","def preprocess(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series, list[str], SimpleImputer]:\n","    \"\"\"\n","    ===== 工夫点②：0を欠損扱い → 補完で安定化 =====\n","    Pimaでは一部の列で 0 が「未計測」を示すことがあるため NaNに変換し中央値補完。\n","    \"\"\"\n","    df = df.copy()\n","\n","    target_col = \"Outcome\"\n","    feature_cols = [c for c in df.columns if c != target_col]\n","\n","    # 0が不自然な列（Pimaでよくある）\n","    zero_as_missing_cols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n","    for c in zero_as_missing_cols:\n","        df.loc[df[c] == 0, c] = np.nan\n","\n","    X = df[feature_cols]\n","    y = df[target_col].astype(int)\n","\n","    imputer = SimpleImputer(strategy=\"median\")\n","    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=feature_cols)\n","\n","    return X_imputed, y, feature_cols, imputer\n","\n","\n","def train_model(X: pd.DataFrame, y: pd.Series) -> tuple[XGBClassifier, dict]:\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n","    )\n","\n","    model = XGBClassifier(\n","        n_estimators=400,\n","        learning_rate=0.05,\n","        max_depth=4,\n","        subsample=0.8,\n","        colsample_bytree=0.8,\n","        reg_alpha=0.1,\n","        reg_lambda=1.0,\n","        gamma=0.0,\n","        objective=\"binary:logistic\",\n","        eval_metric=\"logloss\",\n","        random_state=RANDOM_STATE,\n","        n_jobs=-1,\n","    )\n","\n","    model.fit(X_train, y_train)\n","\n","    y_proba = model.predict_proba(X_test)[:, 1]\n","    y_pred = (y_proba >= 0.5).astype(int)\n","\n","    metrics = {\n","        \"accuracy\": float(accuracy_score(y_test, y_pred)),\n","        \"auc\": float(roc_auc_score(y_test, y_proba)),\n","        \"report\": classification_report(y_test, y_pred),\n","    }\n","\n","    return model, metrics\n","\n","\n","def save_artifacts(model: XGBClassifier, feature_cols: list[str], imputer: SimpleImputer) -> None:\n","    \"\"\"\n","    ===== 工夫点③：特徴量順＋前処理（imputer）も一緒に保存 =====\n","    Streamlit側で同じ前処理と特徴量順を再現して、mismatchを防ぐ。\n","    \"\"\"\n","    artifact = {\n","        \"model\": model,\n","        \"feature_names\": feature_cols,\n","        \"imputer\": imputer,\n","    }\n","    joblib.dump(artifact, MODEL_PATH)\n","    print(f\"Saved model artifact: {MODEL_PATH}\")\n","\n","\n","def save_feature_importance(model: XGBClassifier, feature_cols: list[str]) -> None:\n","    importance = pd.DataFrame(\n","        {\"feature\": feature_cols, \"importance\": model.feature_importances_}\n","    ).sort_values(\"importance\", ascending=False)\n","\n","    importance.to_csv(IMPORTANCE_PATH, index=False)\n","    print(f\"Saved feature importance: {IMPORTANCE_PATH}\")\n","    print(\"\\n=== Feature importance (top) ===\")\n","    print(importance.head(20))\n","\n","\n","def main():\n","    df = load_data(DATA_PATH)\n","    X, y, feature_cols, imputer = preprocess(df)\n","\n","    model, metrics = train_model(X, y)\n","\n","    print(\"=== Evaluation (hold-out test) ===\")\n","    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n","    print(f\"AUC     : {metrics['auc']:.4f}\")\n","    print(\"\\nClassification report:\\n\", metrics[\"report\"])\n","\n","    save_artifacts(model, feature_cols, imputer)\n","    save_feature_importance(model, feature_cols)\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}